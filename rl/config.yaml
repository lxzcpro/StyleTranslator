# 模型配置
model:
  name: "Qwen/Qwen2.5-0.5B-Instruct"
  path: "Z:\\Qwen2.5-0.5B-Instruct"  # 本地模型路径
  device: "auto"  # auto, cpu, cuda

# 训练配置
training:
  num_generations: 4  # 每个原文生成的结果数量
  batch_size: 1
  num_epochs: 1
  max_length: 512
  learning_rate: 1e-5
  beta: 0.04  # GRPO的KL正则化系数
  gamma: 1.0  # 奖励折扣因子

# 奖励模型配置
reward:
  # 风格奖励模型路径
  chinese_bert_path: "path/to/chinese_bert_model"
  english_bert_path: "path/to/english_bert_model"
  
  # 风格类型 (4种风格,需要更换)
  style_types: ["formal", "casual", "technical", "literary"]
  
  # 奖励权重 (格式: 0.2, 语义: 0.7, 风格: 0.1)
  format_reward_weight: 0.2
  semantic_reward_weight: 0.7
  style_reward_weight: 0.1
  
  # COMET语义奖励配置
  comet_model: "wmt22-cometkiwi-da"  # COMET模型名称
  comet_device: "auto"  # COMET模型运行设备: auto, cpu, cuda
  comet_path: None
  
  # 模式切换
  test_mode: true  # true: 测试模式，false: 正式模式

# 数据配置
data:
  train_file: "data/train/train_style.parquet"
  test_file: "data/test/test_style.parquet"
  max_train_samples: 1000
  max_test_samples: 100

# 输出配置
output:
  output_dir: "./outputs"
  logging_steps: 10
  save_steps: 100