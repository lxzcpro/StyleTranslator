chinese:
  model_name: bert-base-chinese
  dataset_path: corpus/ch_data.csv
  max_length: 512
  batch_size: 16
  learning_rate: 2.0e-5
  warmup_steps: 500  # Increased from 10 to 500 for better training stability
  dropout_rate: 0.1
  freeze_bert_layers: 10

english:
  model_name: bert-base-uncased
  dataset_path: corpus/en_data.csv
  max_length: 512
  batch_size: 16
  learning_rate: 2.0e-5
  warmup_steps: 500  # Increased from 10 to 500 for better training stability
  dropout_rate: 0.1
  freeze_bert_layers: 10

# Training settings
training:
  epochs: 10
  num_workers: 4
  accelerator: auto
  devices: 1
  precision: 16-mixed
  gradient_clip_val: 1.0
  accumulate_grad_batches: 1
  val_check_interval: 0.25
  log_every_n_steps: 10

# Data split ratios
data:
  train_ratio: 0.8
  val_ratio: 0.1

# Callbacks
callbacks:
  early_stopping:
    monitor: val_loss
    patience: 3
    mode: min
  checkpoint:
    monitor: val_loss
    mode: min
    save_top_k: 1
    save_last: true

# Wandb settings
wandb:
  project: style-detection
  entity: zhangxuting
  tags:
    - bert
    - style-detection